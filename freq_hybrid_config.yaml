# Config for the Frequency-Aware Self-Distrust Hybrid Model
exp_id: "final_freq_hybrid"
gpu: 0 # Assigned GPU

dataset:
  name: "wikitext"
  config: "wikitext-2-raw-v1"
  tokenizer: "bert-base-uncased"
  max_seq_len: 128
  cache_dir: ".cache"

vocab:
  size: 30522
  mask_token_id: 103

model:
  d_model: 512
  n_head: 8
  num_encoder_layers: 6
  dim_feedforward: 2048
  dropout: 0.1
  use_gated_attention: false
  use_self_conditioning: false

diffusion:
  graph_type: "frequency_hybrid" # Use our new combined graph
  mask_ratio: 0.1 # The successful 10% anchor
  noise_schedule:
    name: "geometric"
    g_min: 0.001
    g_max: 7.0
  num_timesteps: 1000

training:
  batch_size: 64
  num_epochs: 100
  learning_rate: 1.0e-4
  grad_clip: 1.0
  patience: 5
  unconditional_prob: 0.1

logging:
  checkpoint_dir: "checkpoints"
  log_interval: 100
  save_interval: 1

analysis:
  num_samples: 50
  guidance_scale: 1.0
